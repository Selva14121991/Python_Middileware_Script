import os
import zipfile
import pandas as pd
from datetime import datetime
from sqlalchemy import create_engine
import psycopg2
from psycopg2.extras import execute_values

# ================== CONFIGURATION ==================
DB_CONFIG = {
    "host": "4.188.251.57",
    "port": 5432,
    "database": "aidb",
    "user": "aiuser1",
    "password": "Password#12"
}

SCHEMA = "DocAI"
TABLE_HEADERS = "oracle_ap_invoice_headers"
TABLE_LINES = "oracle_ap_invoice_lines"
SUPPLIER_MASTER = "Oracle_Supplier_Master_Details"
TAX_MASTER = "Oracle_Tax_Master_Details"

OUTPUT_FOLDER = r"D:\APInvoice\FBDI\UCMLOAD\Inbound"

# ================== HELPER FUNCTIONS ==================
def clean_nulls(df):
    return df.fillna("")

def add_end_column(df):
    df["END"] = "END"
    return df

def export_to_csv(df, path):
    df.to_csv(path, index=False, header=False, encoding="utf-8-sig")
    print(f"ðŸ“„ Exported CSV â†’ {path}")

def zip_files(file1, file2, zip_path):
    with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
        z.write(file1, os.path.basename(file1))
        z.write(file2, os.path.basename(file2))
    print(f"ðŸ—œ ZIP Created â†’ {zip_path}")

# ================== MAIN PROCESS ==================
if __name__ == "__main__":
    conn = None
    try:
        os.makedirs(OUTPUT_FOLDER, exist_ok=True)

        # ----------------- DATABASE CONNECTION -----------------
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        conn.autocommit = False

        engine = create_engine(
            f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
            f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}"
        )

        # ----------------- STEP 1: LOAD SUPPLIER MASTER -----------------
        supplier_master_query = f"""
            SELECT DISTINCT supplier_name, supplier_number, vendor_site_code, assigned_bu
            FROM "{SCHEMA}"."{SUPPLIER_MASTER}";
        """
        df_supplier_master = pd.read_sql(supplier_master_query, engine)

        update_query = f"""
            UPDATE "{SCHEMA}"."{TABLE_HEADERS}" AS h
            SET supplier_number = data.supplier_number,
                supplier_site = data.vendor_site_code,
                business_unit = data.assigned_bu
            FROM (VALUES %s) AS data(supplier_name, supplier_number, vendor_site_code, assigned_bu)
            WHERE h.supplier_name = data.supplier_name;
        """

        update_data = [
            (row.supplier_name, row.supplier_number, row.vendor_site_code, row.assigned_bu)
            for row in df_supplier_master.itertuples()
        ]

        execute_values(cursor, update_query, update_data)
        conn.commit()
        print("âœ” Bulk updated header table supplier info from master data")

        # ----------------- STEP 2: LOAD HEADER DATA -----------------
        HEADER_REAL_COLS = [
            "invoice_id",
            "business_unit",
            "source",
            "invoice_number",
            "invoice_amount",
            "invoice_date",
            "supplier_name",
            "supplier_number",
            "supplier_site",
            "invoice_currency",
            "payment_currency",
            "description",
            "import_set",
            "invoice_type",
            'NULL AS legal_entity',
            'NULL AS customer_tax_registration_number',
            'NULL AS customer_registration_code',
            'NULL AS first_party_tax_registration_number',
            'NULL AS supplier_tax_registration_number',
            "payment_terms",
            "terms_date",
            'NULL AS goods_received_date',
            'NULL AS invoice_received_date',
            "accounting_date",
            "payment_method",
            "pay_group",
            "pay_alone",
            'NULL AS discountable_amount',
            'NULL AS prepayment_number',
            'NULL AS prepayment_line_number',
            'NULL AS prepayment_application_amount',
            'NULL AS prepayment_accounting_date',
            'NULL AS invoice_includes_prepayment',
            'NULL AS conversion_rate_type',
            'NULL AS conversion_date',
            'NULL AS conversion_rate',
            "liability_combination",
            'NULL AS document_category_code',
            'NULL AS voucher_number',
            'NULL AS Requester_First_Name',
            'NULL AS Requester_Last_Name',
            'NULL AS Requester_Employee_Number',
            'NULL AS delivery_channel_code',
            'NULL AS bank_charge_bearer',
            'NULL AS remit_to_supplier',
            'NULL AS remit_to_supplier_number',
            'NULL AS remit_to_address_name',
            "payment_priority",
            'NULL AS settlement_priority',
            'NULL AS unique_remittance_identifier',
            'NULL AS unique_remittance_identifier_check_digit',
            'NULL AS payment_reason_code',
            'NULL AS payment_reason_comments',
            'NULL AS remittance_message_1',
            'NULL AS remittance_message_2',
            'NULL AS remittance_message_3',
            'NULL AS withholding_tax_group',
            'NULL AS ship_to_location',
            'NULL AS taxation_country',
            'NULL AS document_sub_type',
            'NULL AS tax_invoice_internal_sequence_number',
            'NULL AS supplier_tax_invoice_number',
            'NULL AS tax_invoice_recording_date',
            'NULL AS supplier_tax_invoice_date',
            'NULL AS supplier_tax_invoice_conversion_rate',
            'NULL AS Port_Of_Entry_Code',
            'NULL AS correction_year',
            'NULL AS correction_Period',
            'NULL AS import_document_number',
            'NULL AS import_document_date',
            'NULL AS tax_control_amount',
            "calculate_tax_during_import",
            'NULL AS add_tax_to_invoice_amount',
            'NULL AS attribute_category',
            "attribute_1_fbdi",
            'NULL AS attribute_2_fbdi',
            'NULL AS attribute_3_fbdi',
            'NULL AS attribute_4_fbdi',
            'NULL AS attribute_5_fbdi',
            'NULL AS attribute_6_fbdi',
            'NULL AS attribute_7_fbdi',
            'NULL AS attribute_8_fbdi',
            'NULL AS attribute_9_fbdi',
            'NULL AS attribute_10_fbdi',
            'NULL AS attribute_11_fbdi',
            'NULL AS attribute_12_fbdi',
            'NULL AS attribute_13_fbdi',
            'NULL AS attribute_14_fbdi',
            'NULL AS attribute_15_fbdi',
            'NULL AS attribute_number_1',
            'NULL AS attribute_number_2',
            'NULL AS attribute_number_3',
            'NULL AS attribute_number_4',
            'NULL AS attribute_number_5',
            'NULL AS attribute_date_1',
            'NULL AS attribute_date_2',
            'NULL AS attribute_date_3',
            'NULL AS attribute_date_4',
            'NULL AS attribute_date_5',
            'NULL AS global_attribute_category',
            'NULL AS global_attribute_1',
            'NULL AS global_attribute_2',
            'NULL AS global_attribute_3',
            'NULL AS global_attribute_4',
            'NULL AS global_attribute_5',
            'NULL AS global_attribute_6',
            'NULL AS global_attribute_7',
            'NULL AS global_attribute_8',
            'NULL AS global_attribute_9',
            'NULL AS global_attribute_10',
            'NULL AS global_attribute_11',
            'NULL AS global_attribute_12',
            'NULL AS global_attribute_13',
            'NULL AS global_attribute_14',
            'NULL AS global_attribute_15',
            'NULL AS global_attribute_16',
            'NULL AS global_attribute_17',
            'NULL AS global_attribute_18',
            'NULL AS global_attribute_19',
            'NULL AS global_attribute_20',
            'NULL AS global_attribute_number_1',
            'NULL AS global_attribute_number_2',
            'NULL AS global_attribute_number_3',
            'NULL AS global_attribute_number_4',
            'NULL AS global_attribute_number_5',
            'NULL AS global_attribute_date_1',
            'NULL AS global_attribute_date_2',
            'NULL AS global_attribute_date_3',
            'NULL AS global_attribute_date_4',
            'NULL AS global_attribute_date_5',
            'NULL AS url_attachments',
            'NULL AS remit_to_bank_account_number',
            'NULL AS supplier_iban',
            'NULL AS requester_email_address',
            'NULL AS intercompany_crosscharge_flag',
            'NULL AS remit_to_digital_account'
        ]

        query_headers = f"""
            SELECT {', '.join(HEADER_REAL_COLS)}
            FROM "{SCHEMA}"."{TABLE_HEADERS}"
            WHERE status = 'A' 
              AND business_unit <> ''
              AND (erp_interface_status IS NULL OR erp_interface_status = 'Error');
        """
        df_headers = pd.read_sql(query_headers, engine)
        print(f"âœ… Header Records Loaded: {len(df_headers)}")

        df_headers["source"] = df_headers["source"].astype(str).str.title()
        df_headers["invoice_type"] = df_headers["invoice_type"].fillna("STANDARD").replace(["", "None"], "STANDARD").str.upper()
        df_headers["payment_terms"] = df_headers["payment_terms"].fillna("Immediate").replace(["", "None"], "Immediate").astype(str)

        # ----------------- STEP 3: LOAD LINE DATA -----------------
        LINES_REAL_COLS = [
            "invoice_id",
            "line_number",
            "line_type",
            "amount",
            "invoice_quantity",
            "unit_price",
            "uom",
            "description",
            "po_number",
            "po_line_number",
            "po_schedule_number",
            "po_distribution_number",
            'NULL AS item_description',
            'NULL AS po_release_number',
            'NULL AS purchasing_category',
            'NULL AS receipt_number',
            'NULL AS receipt_line_number',
            'NULL AS consumption_advice_number',
            'NULL AS consumption_advice_line_number',
            'NULL AS packing_slip',
            'NULL AS final_match',
            'NULL AS distribution_combination',
            'NULL AS distribution_set',
            'NULL AS accounting_date',
            'NULL AS overlay_account_segment',
            'NULL AS overlay_primary_balancing_segment',
            'NULL AS overlay_cost_center_segment',
            "tax_classification_code",
            'NULL AS ship_to_location',
            'NULL AS ship_from_location',
            'NULL AS location_of_final_discharge',
            'NULL AS transaction_business_category',
            'NULL AS product_fiscal_classification',
            'NULL AS intended_use',
            'NULL AS user_defined_fiscal_classification',
            'NULL AS product_type',
            'NULL AS assessable_value',
            'NULL AS product_category',
             "tax_control_amount",
            'NULL AS  tax_regime_code',
            'NULL AS tax',
            'NULL AS tax_status_code',
            'NULL AS tax_jurisdiction_code',
            "tax_rate_code",
            "tax_rate",
            'NULL AS withholding_tax_group',
            'NULL AS income_tax_type',
            'NULL AS income_tax_region',
            "prorate_across_all_item_lines",
            "line_group_number",
            'NULL AS cost_factor_name',
            'NULL AS statistical_quantity',
            "track_as_asset",
            'NULL AS asset_book_type_code',
            'NULL AS asset_category_id',
            'NULL AS serial_number',
            'NULL AS manufacturer',
            'NULL AS model_number',
            'NULL AS warranty_number',
            "price_correction_line",
            'NULL AS price_correction_invoice_number',
            'NULL AS price_correction_invoice_line_number',
            'NULL AS attribute_category',
            'NULL AS attribute_1_fbdi',
            'NULL AS attribute_2_fbdi',
            'NULL AS attribute_3_fbdi',
            'NULL AS attribute_4_fbdi',
            'NULL AS attribute_5_fbdi',
            'NULL AS attribute_6_fbdi',
            'NULL AS attribute_7_fbdi',
            'NULL AS attribute_8_fbdi',
            'NULL AS attribute_9_fbdi',
            'NULL AS attribute_10_fbdi',
            'NULL AS attribute_11_fbdi',
            'NULL AS attribute_12_fbdi',
            'NULL AS attribute_13_fbdi',
            'NULL AS attribute_14_fbdi',
            'NULL AS attribute_15_fbdi',
            'NULL AS attribute_number_1',
            'NULL AS attribute_number_2',
            'NULL AS attribute_number_3',
            'NULL AS attribute_number_4',
            'NULL AS attribute_number_5',
            'NULL AS attribute_date_1',
            'NULL AS attribute_date_2',
            'NULL AS attribute_date_3',
            'NULL AS attribute_date_4',
            'NULL AS attribute_date_5',
            'NULL AS global_attribute_category',
            'NULL AS global_attribute_1',
            'NULL AS global_attribute_2',
            'NULL AS global_attribute_3',
            'NULL AS global_attribute_4',
            'NULL AS global_attribute_5',
            'NULL AS global_attribute_6',
            'NULL AS global_attribute_7',
            'NULL AS global_attribute_8',
            'NULL AS global_attribute_9',
            'NULL AS global_attribute_10',
            'NULL AS global_attribute_11',
            'NULL AS global_attribute_12',
            'NULL AS global_attribute_13',
            'NULL AS global_attribute_14',
            'NULL AS global_attribute_15',
            'NULL AS global_attribute_16',
            'NULL AS global_attribute_17',
            'NULL AS global_attribute_18',
            'NULL AS global_attribute_19',
            'NULL AS global_attribute_20',
            'NULL AS global_attribute_number_1',
            'NULL AS global_attribute_number_2',
            'NULL AS global_attribute_number_3',
            'NULL AS global_attribute_number_4',
            'NULL AS global_attribute_number_5',
            'NULL AS global_attribute_date_1',
            'NULL AS global_attribute_date_2',
            'NULL AS global_attribute_date_3',
            'NULL AS global_attribute_date_4',
            'NULL AS global_attribute_date_5',
            'NULL AS expenditure_item_date',
            'NULL AS project_number',
            'NULL AS task_number',
            'NULL AS expenditure_type',
            'NULL AS expenditure_organization',
            'NULL AS fiscal_charge_type',
            'NULL AS project_name',
            'NULL AS task_name'
        ]

        query_lines = f"""
            SELECT {', '.join(LINES_REAL_COLS)}
            FROM "{SCHEMA}"."{TABLE_LINES}"
            WHERE invoice_id IN (
                SELECT invoice_id FROM "{SCHEMA}"."{TABLE_HEADERS}"
                WHERE status = 'A' 
                  AND business_unit <> ''
                  AND (erp_interface_status IS NULL OR erp_interface_status = 'Error')
            );
        """
        df_lines = pd.read_sql(query_lines, engine)
        df_lines["line_type"] = df_lines["line_type"].astype(str).str.upper()
#===============================
        # ======================================================================
        #   AUTO-GENERATE TAX LINES (USING ITEM line_amount Ã— tax_rate)
        # ======================================================================

        if len(df_headers) > 0:
            print("ðŸ“Œ Header records found â†’ proceeding with TAX line generation...")

        # Fetch ITEM lines for eligible invoices
        orig_lines_query = f"""
              SELECT invoice_id, line_number, line_type,
                     unit_price, invoice_quantity, line_amount, tax_rate
              FROM "{SCHEMA}"."{TABLE_LINES}"
              WHERE invoice_id IN (
                  SELECT invoice_id
                  FROM "{SCHEMA}"."{TABLE_HEADERS}"
                  WHERE status = 'A'
                    AND business_unit <> ''
              );
        """
        df_lines = pd.read_sql(orig_lines_query, engine)
        df_lines["line_type"] = df_lines["line_type"].astype(str).str.upper()

        mask_item = df_lines["line_type"] == "ITEM"

        # ----------------- STEP 1: RECALCULATE ITEM line_amount -----------------
        df_lines["unit_price"] = pd.to_numeric(df_lines["unit_price"], errors='coerce').fillna(0.0)
        df_lines["invoice_quantity"] = pd.to_numeric(df_lines["invoice_quantity"], errors='coerce').fillna(0.0)
        df_lines.loc[mask_item, "line_amount"] = (
                df_lines.loc[mask_item, "unit_price"] * df_lines.loc[mask_item, "invoice_quantity"]
        ).round(2)


        # ----------------- STEP 2: CALCULATE tax_control_amount -----------------
        def normalize_tax_rate(x):
            if pd.isna(x):
                return 0.0
            x = float(x)
            return x * 100 if x < 1 else x


        df_lines["tax_rate"] = pd.to_numeric(df_lines["tax_rate"], errors='coerce').fillna(0.0)
        df_lines.loc[mask_item, "adjusted_tax_rate"] = df_lines.loc[mask_item, "tax_rate"].apply(normalize_tax_rate)
        df_lines.loc[mask_item, "tax_control_amount"] = (
                df_lines.loc[mask_item, "line_amount"] * df_lines.loc[mask_item, "adjusted_tax_rate"] / 100
        ).round(2)

        # ----------------- STEP 3: BULK UPDATE tax_control_amount -----------------
        update_values = [
            (float(row.tax_control_amount), int(row.invoice_id), int(row.line_number))
            for row in df_lines[mask_item].itertuples()
        ]
        update_sql = f"""
            UPDATE "{SCHEMA}"."{TABLE_LINES}" AS L
            SET tax_control_amount = data.tax_control_amount
            FROM (VALUES %s) AS data(tax_control_amount, invoice_id, line_number)
            WHERE L.invoice_id = data.invoice_id::BIGINT
              AND L.line_number = data.line_number::INT;
        """
        execute_values(cursor, update_sql, update_values)
        conn.commit()
        print(f"âœ” Updated tax_control_amount for {len(update_values)} ITEM lines.")

        # ----------------- STEP 4: GENERATE TAX LINES -----------------
        auto_tax_lines = []

        for invoice_id, group in df_lines.groupby("invoice_id"):

            # Skip if TAX line already exists
            if "TAX" in group["line_type"].values:
                continue

            item_lines = group[group["line_type"] == "ITEM"]
            if item_lines.empty:
                continue

            next_line_number = group["line_number"].max() + 1
            tax_groups = item_lines.groupby("adjusted_tax_rate")

            for tax_rate, grp in tax_groups:
                tax_amount = grp["tax_control_amount"].sum().round(2)
                auto_tax_lines.append(
                    (
                        int(invoice_id),
                        int(next_line_number),
                        "TAX",
                        float(tax_amount),
                        float(tax_rate)
                    )
                )
                next_line_number += 1

        # ----------------- STEP 5: INSERT TAX LINES -----------------
        if auto_tax_lines:
            print(f"âž• Creating {len(auto_tax_lines)} TAX lines...")

            insert_sql = f"""
                  INSERT INTO "{SCHEMA}"."{TABLE_LINES}"
                  (invoice_id, line_number, line_type, amount, tax_rate)
                  VALUES %s;
              """
            execute_values(cursor, insert_sql, auto_tax_lines)
            conn.commit()
            print("âœ” Auto-generated TAX lines inserted.")
        else:
            print("âœ” No missing TAX lines detected.")

        # ===============================
        # ======================================================================
        #   STEP 4: APPLY TAX MASTER (your original code continues unchanged)
        # ======================================================================

        tax_lookup_query = f"""
            SELECT APL.invoice_id, APL.line_number, APL.tax_rate, APH.business_unit
            FROM "{SCHEMA}"."{TABLE_LINES}" APL
            JOIN "{SCHEMA}"."{TABLE_HEADERS}" APH
              ON APH.invoice_id = APL.invoice_id
            WHERE APL.line_type = 'TAX';
        """
        df_tax_lookup = pd.read_sql(tax_lookup_query, engine)

        df_tax_master = pd.read_sql(
            f'SELECT DISTINCT tax_regime_code, tax, tax_status_code, tax_rate_code, tax_rate, bu_name FROM "{SCHEMA}"."{TAX_MASTER}"',
            engine
        )


        def normalize_tax_rate(x):
            try:
                if pd.isna(x):
                    return 0.0
                x = float(x)
                if x < 1:
                    x = x * 100
                return round(x, 2)
            except:
                return 0.0


        df_tax_lookup['tax_rate'] = df_tax_lookup['tax_rate'].apply(normalize_tax_rate)
        df_tax_master['tax_rate'] = df_tax_master['tax_rate'].apply(normalize_tax_rate)

        df_tax_merged = pd.merge(
            df_tax_lookup,
            df_tax_master,
            left_on=['tax_rate', 'business_unit'],
            right_on=['tax_rate', 'bu_name'],
            how='left'
        )

        df_tax_merged['tax_regime_code'] = df_tax_merged['tax_regime_code'].fillna('')
        df_tax_merged['tax'] = df_tax_merged['tax'].fillna(0)
        df_tax_merged['tax_status_code'] = df_tax_merged['tax_status_code'].fillna('')
        df_tax_merged['tax_rate_code'] = df_tax_merged['tax_rate_code'].fillna('')
        df_tax_merged['tax_rate'] = df_tax_merged['tax_rate'].fillna(0)

        tax_update_values = [
            (
                str(row.tax_rate_code),
                float(row.tax_rate),
                int(row.invoice_id),
                int(row.line_number)
            )
            for row in df_tax_merged.itertuples()
        ]

        update_sql = f"""
        UPDATE "{SCHEMA}"."{TABLE_LINES}" AS L
        SET 
            tax_rate_code = data.tax_rate_code,
            tax_rate = data.tax_rate
        FROM (VALUES %s) AS data(
            tax_rate_code, tax_rate, invoice_id, line_number
        )
        WHERE L.invoice_id = data.invoice_id::BIGINT
          AND L.line_number = data.line_number::INT;
        """
        execute_values(cursor, update_sql, tax_update_values)
        conn.commit()
        print("âœ” Tax master updated (ONLY tax_rate_code + tax_rate)")

        # ------------------------------------------------------------
        # REFRESH LINE DATA AFTER TAX MASTER UPDATE
        # ------------------------------------------------------------
        print("ðŸ”„ Reloading invoice lines after tax master update...")

        df_lines = pd.read_sql(query_lines, engine)
        df_lines["line_type"] = df_lines["line_type"].astype(str).str.upper()

        # ----------------- STEP 5: TAX CLASSIFICATION -----------------
        df_lines["tax_classification_code"] = df_lines.apply(
            lambda r: r["tax_classification_code"] if str(r["line_type"]).upper() == "TAX" else "",
            axis=1
        )

        # ----------------- STEP 4B: UPDATE LINE AMOUNTS -----------------
        print("ðŸ”„ Updating line amounts based on unit_price * invoice_quantity...")

        # Ensure numeric types
        df_lines["unit_price"] = pd.to_numeric(df_lines["unit_price"], errors='coerce').fillna(0.0)
        df_lines["invoice_quantity"] = pd.to_numeric(df_lines["invoice_quantity"], errors='coerce').fillna(0.0)
        df_lines["tax_control_amount"] = pd.to_numeric(df_lines["tax_control_amount"], errors='coerce').fillna(0.0)

        # Only update ITEM lines (skip TAX lines)
        mask_item_lines = df_lines["line_type"].str.upper() != "TAX"

        # Recalculate amount
        df_lines.loc[mask_item_lines, "amount"] = (
                df_lines.loc[mask_item_lines, "unit_price"] * df_lines.loc[mask_item_lines, "invoice_quantity"]
        )

        # Update the database
        lines_to_update = df_lines[mask_item_lines][["invoice_id", "line_number", "amount"]].copy()
        update_lines_sql = f"""
            UPDATE "{SCHEMA}"."{TABLE_LINES}" AS L
            SET amount = data.amount
            FROM (VALUES %s) AS data(invoice_id, line_number, amount)
            WHERE L.invoice_id = data.invoice_id::BIGINT
              AND L.line_number = data.line_number::INT;
        """

        # Convert NumPy types to native Python types
        update_values = [
            (int(row[0]), int(row[1]), float(row[2]))
            for row in lines_to_update.to_numpy()
        ]

        execute_values(cursor, update_lines_sql, update_values)
        conn.commit()

        print(f"âœ” Updated {len(lines_to_update)} invoice line amounts (unit_price Ã— invoice_quantity)")

        # ----------------- REFRESH df_lines -----------------
        print("ðŸ”„ Refreshing invoice lines to reflect updated amounts...")
        df_lines = pd.read_sql(query_lines, engine)
        df_lines["line_type"] = df_lines["line_type"].astype(str).str.upper()

        # ----------------- STEP 6: GENERATE FBDI -----------------
        for bu in df_headers['business_unit'].unique():
            print(f"\nðŸš€ GENERATING FBDI FOR BU: {bu}")
            hdf = df_headers[df_headers['business_unit'] == bu].copy()
            ldf = df_lines[df_lines['invoice_id'].isin(hdf['invoice_id'])].copy()
            # ----------------- CLEAR TAX INFO FOR ITEM LINES ONLY FOR CSV EXPORT -----------------
            mask_item_lines_csv = ldf["line_type"] != "TAX"
            ldf.loc[mask_item_lines_csv, ["tax_rate", "tax_control_amount", "tax_rate_code"]] = None
            print("â„¹ ITEM lines tax fields set to NULL in CSV export only")

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            auto_value = f"BDOC_{bu}_{timestamp}"
            hdf["attribute_1_fbdi"] = auto_value
            print(f"âœ” attribute_1_fbdi set to â†’ {auto_value}")

            hdf = add_end_column(clean_nulls(hdf))
            ldf = add_end_column(clean_nulls(ldf))

            header_csv = os.path.join(OUTPUT_FOLDER, "ApInvoicesInterface.csv")
            lines_csv = os.path.join(OUTPUT_FOLDER, "ApInvoiceLinesInterface.csv")
            export_to_csv(hdf, header_csv)
            export_to_csv(ldf, lines_csv)

            zip_path = os.path.join(
                OUTPUT_FOLDER,
                f"{bu.replace(' ', '_')}_apinvoiceimport_{timestamp}.zip"
            )
            zip_files(header_csv, lines_csv, zip_path)

            # ----------------- STEP 7: UPDATE HEADER STATUS -----------------
            df_inv = pd.read_csv(header_csv, header=None)
            invoice_numbers = df_inv[3].dropna().astype(str).tolist()
            update_header_sql = f"""
                UPDATE "{SCHEMA}"."{TABLE_HEADERS}"
                SET status = 'P',
                    erp_interface_status = 'Processed',
                    erp_interface_description = NULL
                WHERE invoice_number = ANY(%s);
            """
            cursor.execute(update_header_sql, (invoice_numbers,))
            conn.commit()
            print("âœ” Header status updated to P / Processed")

            os.remove(header_csv)
            os.remove(lines_csv)

    except Exception as e:
        print("âŒ ERROR:", e)

    finally:
        if conn:
            conn.close()
            print("ðŸ”’ Database Closed")
